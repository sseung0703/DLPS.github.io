---
layout: post
title: "2020_4th_quarter"
date: 2020-10-08
image_url: https://user-images.githubusercontent.com/25892000/103460520-16368800-4d5a-11eb-8400-4fe5048f2c7e.png
mathjax: true
comments: true
---

# Self-training with Noisy Student improves ImageNet classification
## Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le 
### 발표자: 강진구 [[paper link](https://arxiv.org/pdf/1911.04252.pdf), [presentation material](https://drive.google.com/file/d/1GIAu3CTYjv5Noj6pLGh7em-66MGW_nfW/view)]
- Semi-supervised 방법인 Noisy student training을 적용하여 ImageNet SOTA를 경신한 논문입니다. 
- 수많은 Unlabeled 데이터들을 잘 활용하는 방법을 소개하는데 그 방법이 매우 간단합니다. Teacher model과 Student model을 정의하고 Teacher model이 Unlabeled 데이터에 대해 labeling해서 Student model에게 주면 Student model은 그 이미지와 Teacher model이 labeling해 준 pseudo-label을 해당 이미지의 label로 여기고 학습합니다. 첫 Teacher model은 사람이 labeling한 데이터셋을 사용합니다. 첫 Teacher model이 만들어낸 Student model은 그 다음 generation의 Teacher model이 되어 새로운 Student model을 만들어 냅니다. 이 방법으로 여러번 Generation을 거치면서 점점 더 좋은 성능의 모델이 만들어 집니다.
- Teacher model이 Unlabeled data를 labeling 할 때는 이미지에 noise를 섞지 않고, Student model이 pseudo-label을 학습할 때는 noise를 강하게 섞는 것이 이 기법의 핵심입니다. 또한 generation이 거듭되면서 Student model은 기존 Teacher model보다 더 많은 파라미터를 가진 큰 모델로 정의함으로써 더 어려운 문제를 풀 수 있게 만들어 줍니다. 
<p align="center">
<img width="538" alt="Illustration of the Noisy Student Training." src="https://user-images.githubusercontent.com/25892000/103460520-16368800-4d5a-11eb-8400-4fe5048f2c7e.png">

</p>

***

# What does an End-to-End Dialect Identification Model Learn about Non-dialectal Information?
## Shammur A Chowdhury, Ahmed Ali, Suwon Shon, and James Glass, 2020
### 발표자: 지승훈 [[paper link](http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=388&id=401), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5fe086f4b5c61f70fcad0eb3/33852bab1b6995e4d8d0bd683ca81ab0/20201223_presentation.pdf)]
- 딥 러닝 모델은 layer들을 지날 수록 주어진 task에 어떻게 가까워 지는지를 사람이 해석할 수 있게(interpretable하게) 나타내고 알아보려는 여러 가지 시도들이 있어 왔습니다. 그것을 end-to-end 방언 식별(dialect classification) 모델을 통해 수행해 본 논문으로, 방언 관련 task인 지역 방언 식별(regional dialect classification), 방언과 관련이 없는 성별 식별(gender classification), 화자 검증(speaker verification)과 언어 식별(language identification), 그리고 음성의 채널 정보를 필요로 하는 채널 식별(channel classification)을 proxy task로 설정하여 방언을 식별하는 모델이 input data를 처리하는 과정에서 방언과 관계 있는 정보와 그렇지 않은 정보를 얼마나 잘 가지고 있는지를 나타내 보고자 했습니다.
- 아랍어의 국가 단위 방언을 식별하는 ADI(Arabic Dialect Identification) 모델은 4개의 CNN layer, 2개의 fully-connected layer로 이루어져 있습니다. 이 모델의 output, 즉 intermediate embedding을 따로 뽑은 후, 앞에서 말한 5개의 proxy task 수행을 목적으로 미리 훈련된 간단한 fully-connected layer 모델에 이들을 input으로 넣었을 때 이들 proxy task 모델의 성능은 어떻게 나타나는지 분석해 봅니다.
- 하지만 이것이 정말로 딥 러닝 모델의 중간 형태를 아는 것이라고 할 수 있는가에는 아직 물음표를 붙일 수밖에 없습니다. 그러나 이와 같은 연구로 우리는 딥 러닝 모델을 이해한다는 것에 한 발짝 더 가까워질 수 있을 것입니다.

<p align="center">
<img alt="Illustrated ADI model and the proxy tasks introduced in the paper." src="https://user-images.githubusercontent.com/54841617/103462065-176db200-4d66-11eb-8ecd-a455b024a929.png">
